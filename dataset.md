We have published the full-size [raw dataset](https://share.weiyun.com/avv8jpv4) without processing and the selected 500 [processed samples](https://share.weiyun.com/Tk3mm9O0) for review. By downloading the data, you accept and agree to the terms (TODO) of this license.



## File Structure

* **log.xlsx**: logbook with the recording parameters of all takes
* **subjects.csv**: the list of the subjects participating in the experiments
* **objects.csv**: the list of used objects
* ***data/***
  * ***xxxxxx/***: take folder named by the take id e.g. 000000
    * [***raw/***](#raw-data): raw data directly exported by each recording device
    * [***processed/***](#processed-data): formatted data derived from raw data
* ***annotations/***
  * [**xxxxxx.json**](#annotation): annotation result for the take id e.g. 000000



### Raw Data

* ***hand/***: hand pose data generated by Hand Engine
  * **P1L.csv** / **P1R.csv**: sensor reading and hand pose data of left (L) and right (R) hand
  * **P1LMeta.json** / **P1RMeta.json**: metadata about the hardware and recording setting
  * **P1L.cal** / **P1R.cal**: calibration data
  * **P1L.fbx** / **P1R.fbx**: hand model saved in the fbx file format
* **17471.svo / 24483054.svo / 28280967.svo**: the source recording files of ZED depth camera with videos of left and right views and metadata.
* **17471.csv / 24483054.csv / 28280967.csv**: the timestamps of the frames in video.
* **event_xxxxxxxx.raw**: the raw output of the event camera. 
* **event.bias**: event sensor settings.
* **optitrack.csv**



### Processed Data

* **alignment.json**
* ***rgbd0/***: depth map and the frames of left view RGB images and normalized depth images from the fixed third person view depth camera (SN: 17471)
  * **left_xxxx.png**: RGB image produced by the left view camera. The digits represent the frame numbering.
  * **depth_xxxx.png**: normalized depth images. Depth increases as the color darkens. The digits represent the frame numbering.
  * **depth.npy**: 3-dimensional numpy arrary holding the unnormalized depth estimation of each frame
* ***rgbd1/***: similar data as *rgbd0/* but from the dynamic egocentric view depth camera (SN: 24483054).
* ***rgbd2/***: similar data as *rgbd0/* but from the fixed egocentric view depth camera (SN: 28280967).
* ***rgbd0_ts.csv***: the timestamps of rgbd0 frames. This is exactly the same timestamp files as /raw/17471.csv except renamed to be more interpretable.
* ***rgbd1_ts.csv***: similar data as rgbd0_ts.csv but for rgbd1 frames.
* ***rgbd2_ts.csv***: similar data as rgbd0_ts.csv but for rgbd2 frames.
* **event_xypt.csv**: the decoded [Contrast Detector (CD) events](https://docs.prophesee.ai/stable/concepts.html#event-generation)
* ***event/***: frame-based visualization of events
  * **xxxx.jpg**: a frame visualization of events accumulated in a fixed time span (1/60 second for 60 FPS).
* **event_frames_ts.csv**: timestamps of each event frame in the above directory *event/*.
* **left_hand_pose.csv**: the pose data of the left hand
* **right_hand_pose.csv**: the pose data of the right hand
* **sub1_head_motion.csv**: the position and orientation of the subject1's helmet
* **sub1_left_hand_motion.csv**: the subject1's  left hand motion
* **sub1_right_hand_motion.csv**: the subject1's  right hand motion
* **sub2_head_motion.csv**: the subject2's  head motion



###  Annotation

* **status**: annotation status.
  * 0: not finished
  * 1: finished
  * -1: problematic, need further inspect
* **take_id**: the id of the take
* **object**: the name of the object being thrown or caught in this take
* **catch_result**: the result of catching
  * 0: failed
  * 1: success
* **sub1_cmd**: the command given to the primary subject to instruct the behavior of throwing or catching. Please refer to log.xlsx for the explanation of the attributes below.
  * **subject_id**: the id of the primary subject
  * **hand**
  * **position**
  * **action**
* **sub2_cmd**: the command given to the auxiliary subject.
  * **subject_id**: the id of the auxiliary subject
  * **hand**
  * **position**
  * **action**
  * **hand_vertical**
  * **hand_horizontal**: this attribute is only given when the action to be performed by the auxiliary subject is catch.
  * **throwing_speed**: this is only given when the action to be performed by the auxiliary subject is throw
* **throw**: annotation data for the action throw.
  * **hand**: left, right or both hands used to throw the object
  * **hand_vertical_thrower**: the vertical position of the hand of the thrower at moment *throw*.
  * **hand_vertical_catcher**: the vertical position of the catcher's hand(s) at moment *throw*.
  * **hand_horizontal_thrower**: the horizontal position of the thrower's hand(s) at moment *throw*.
  * **hand_horizontal_catcher**: the horizontal position of the catcher's hand(s) at moment *throw*.
  * **position_thrower**: the position of the thrower in the local coordinates at moment *throw*. 
    * x, y
  * **position_catcher**: the position of the catcher in the local coordinates at moment *throw*.
  * **time_point**: the timestamps of each stream at moment *throw*.
    * stream id
      * frame: the frame number of the stream
      * timestamp: the timestamp of the stream
* **catch**: annotation data for the action catch
  * **hand**: left, right or both hands used to catch the object
  * **hand_vertical**: the vertical position of the catcher's hand(s) at moment *catch (stable)*.
  * **hand_horizontal**: the horizontal position of the catcher's hand(s) at moment *catch (stable)*.
  * **position**: the position of the catcher in the local coordinates at moment *catch (touch)*.
  * **time_point_touch**: the timestamps of each stream at moment *catch (touch)*.
  * **time_point_stable**: the timestamps of each stream at moment *catch (stable)*.