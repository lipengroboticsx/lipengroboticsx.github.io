download instruction

## File Structure

* **log.xlsx**: logbook with the recording parameters of all takes
* **subjects.csv**: the list of the subjects participating in the experiments
* **objects.csv**: the list of used objects
* ***data/***
  * ***xxxxxx/***: take folder named by the take id e.g. 000000
    * [***raw/***](#raw-data): raw data directly exported by each recording device
    * [***processed/***](#processed-data): formatted data derived from raw data
* ***annotations/***
  * [**xxxxxx.json**](#annotation): annotation result for the take id e.g. 000000



### Raw Data

* ***hand/***: hand pose data generated by Hand Engine
  * **P1L.csv** / **P1R.csv**: sensor reading and hand pose data of left (L) and right (R) hand
  * **P1LMeta.json** / **P1RMeta.json**: metadata about the hardware and recording setting
  * **P1L.cal** / **P1R.cal**: calibration data
  * **P1L.fbx** / **P1R.fbx**: hand model saved in the fbx file format
* **17471.svo / 24483054.svo / 28280967.svo**: the source recording files of ZED depth camera with videos of left and right views and metadata.
* **17471.csv / 24483054.csv / 28280967.csv**: the timestamps of the frames in video.
* **event_xxxxxxxx.raw**: the raw output of the event camera. 
* **event.bias**: event sensor settings.
* **optitrack.csv**



### Processed Data

* **alignment.json**
* ***rgbd0/***: depth map and the frames of left view RGB images and normalized depth images from the fixed third person view depth camera (SN: 17471)
  * **left_xxxx.png**: RGB image produced by the left view camera. The digits represent the frame numbering.
  * **depth_xxxx.png**: normalized depth images. Depth increases as the color darkens. The digits represent the frame numbering.
  * **depth.npy**: 3-dimensional numpy arrary holding the unnormalized depth estimation of each frame
* ***rgbd1/***: similar data as *rgbd0/* but from the dynamic egocentric view depth camera (SN: 24483054).
* ***rgbd2/***: similar data as *rgbd0/* but from the fixed egocentric view depth camera (SN: 28280967).
* ***rgbd0_ts.csv***: the timestamps of rgbd0 frames. This is exactly the same timestamp files as /raw/17471.csv except renamed to be more interpretable.
* ***rgbd1_ts.csv***: similar data as rgbd0_ts.csv but for rgbd1 frames.
* ***rgbd2_ts.csv***: similar data as rgbd0_ts.csv but for rgbd2 frames.
* **event_xypt.csv**: the decoded [Contrast Detector (CD) events](https://docs.prophesee.ai/stable/concepts.html#event-generation)
* ***event/***: frame-based visualization of events
  * **xxxx.jpg**: a frame visualization of events accumulated in a fixed time span (1/60 second for 60 FPS).
* **event_frames_ts.csv**: timestamps of each event frame in the above directory *event/*.
* **left_hand_pose.csv**: the pose data of the left hand
* **right_hand_pose.csv**: the pose data of the right hand
* **sub1_head_motion.csv**: the position and orientation of the subject1's helmet
* **sub1_left_hand_motion.csv**: the subject1's  left hand motion
* **sub1_right_hand_motion.csv**: the subject1's  right hand motion
* **sub2_head_motion.csv**: the subject2's  head motion



###  Annotation

* status: annotation status. TODO: be removed in the released version.
  * 0: not finished
  * 1: finished
  * -1: problematic, need further inspect
* take_id: the id of the take
* object: the name of the object being thrown or caught in this take
* catch_result: the result of catching
  * 0: failed
  * 1: success
* sub1_cmd: the command given to the subject 1 to instruct the behavior of throwing or catching. Please refer to log.xlsx for the explanation of the attributes below.
  * subject_id: the id of the subject 1
  * hand
  * position
  * action
* sub2_cmd: the command given to the subject 2.
  * subject_id: the id of the subject 2
  * hand
  * position
  * action
  * hand_vertical
  * hand_horizontal: this attribute is only given when the action to be performed by the subject 2 is catch.
  * throwing_speed: this is only given when the action to be performed by the subject 2 is throw
* throw: annotation data for the action throw.
  * hand: single or both hands for throwing the object
  * hand_vertical_thrower: the relative vertical position of the hand of the thrower at the throwing time point.
    * same options as above
  * hand_vertical_catcher: the relative vertical position of the hand of the catcher at the throwing time point.
  * hand_horizontal_thrower: the relative horizontal position of the hand of the thrower at the throwing time point.
  * hand_horizontal_catcher: the relative horizontal position of the hand of the catcher at the throwing time point.
  * position_thrower: the position of the thrower in the local coordinates at the throwing time point. 
    * x, z
  * position_catcher: the position of the catcher in the local coordinates at the throwing time point.
  * time_point: the timestamps of each stream at the throwing time point. An object is concerned as thrown out when there is no contact observed between the object and the hand.
    * stream id
      * frame: the frame number of the corresponding stream
      * timestamp: the timestamp of the corresponding stream (retrieved from the corresponding timestamp file)
* catch: annotation data for the action catch
  * hand: single or both hands for catching the object
  * hand_vertical: the relative vertical position of the hand of the catcher at the catching time point (touch).
  * hand_horizontal: the relative horizontal position of the hand of the catcher at the catching time point (touch).
  * position: the position of the catcher in the local coordinates at the catching time point (touch).
  * time_point_touch: the timestamps of each stream when catching happens (i.e., when the hand of the catcher first touches the object in the flight).
    * same data format as above
  * time_point_stable: the timestamps of each stream when catching stablizes (i.e., the pose between the hands and the object keeps, relatively, approximately static).